version: '3.8'

services:
  streamlit_app:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: streamlit_app
    env_file:
      - .env
    volumes:
      - .:/app
      - pdf_storage:/app/uploads
      - vector_storage:/app/vector_db
      - chroma_db:/app/chroma_db
    ports:
      - "8501:8501"
    depends_on:
      - ollama
    deploy:
      resources:
        limits:
          cpus: '2.00'
          memory: 2G

  ollama:
    build:
      context: .
      dockerfile: Dockerfile.ollama
    container_name: ollama
    ports:
      - "11434:11434"
    volumes:
      - .:/app   # Mount the current directory for scripts like entrypoint.sh
      - llama_models:/root/.ollama/models  # Persistent storage for models
    entrypoint: ["/bin/bash", "/app/entrypoint.sh"]
    deploy:
      resources:
        limits:
          cpus: '2.00'
          memory: 8G  # Increase memory allocation

volumes:
  pdf_storage:
  vector_storage:
  chroma_db:
  llama_models:  # New volume for model data
